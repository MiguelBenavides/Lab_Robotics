{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universidad de Monterrey\n",
    "\n",
    "\n",
    "## División de Ingenierías\n",
    "\n",
    "\n",
    "### Lab - Robotics\n",
    "\n",
    "\n",
    "Lab 6: Image, color, and space\n",
    "\n",
    "Authors: Miguel Benavides Banda, Laura Aguilera Morales\n",
    "\n",
    "\n",
    "### Introduction\n",
    "\n",
    "The following practice consists on retrieving image properties, such as number of channels and image resolution and get the intensity values of pixels and modify them in order to edit images and set a region of interest, as well as spitting and merging image channels, and performing bitwise operations. We will also use codes from previous labs in order to blend images and measure the code performance. In this report only one code will be shown but as explained before, this code contains multiple aspects learned previously and throughout this lab.\n",
    "\n",
    "\n",
    "\n",
    "### Procedure\n",
    "\n",
    "For this practice, the following tools were required: \n",
    "\n",
    "* Raspberry Pi with WiFi connection capabilities\n",
    "* Jupyter Notebook\n",
    "* Python >= 3.5.2\n",
    "* OpenCV 3.2\n",
    "* Git\n",
    "* GitHub account\n",
    "* Markdown editor (recommended: ReText 5.3.1)\n",
    "\n",
    "The base codes for the practice was provided by the instructor but the authors of this report also contributed to the program in order to accomplish the desired objective.\n",
    "\n",
    "\n",
    "\n",
    "### Object segmentation using color information\n",
    "\n",
    "Prior to this lab, we have only been converting 3-channel color images to a grayscale single-channel using the `cvtColour` method from the OpenCV library, in order to obtain a full list of color space such as HSV (Hue, Saturation, Value), HLS (Hue, Lightness, Saturation), and the LAB (Lightness, Green-to-Magenta, Blue-to-Yellow), among others, we must first run the following code, which will give us acces to 274 color spaces:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "colour_space_list = [i for i in dir(cv2) if i.startswith('COLOR_')]\n",
    "print(colour_space_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to choose the color space that we'll work with, we have to consider the computer vision application that we're coding, for example, if the application requires to detect the yellow line in the road, the BGR color space will become handy, but for shadowy images, the HSL color space will work better. For this practice, we will use the HSV color space.\n",
    "\n",
    "The base code provided by the teacher segments blue color objects using two main methods: cvtColor and inRange. The method `hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)` converts the current frame being adquired by a webcam camera from the RGB color space into the HSV color space, and the method `mask = cv2.inRange(hsv, lower_blue, upper_blue)` creates a mask image, which will be a binary image with high pixel intensity values in those regions where blue color objects are detected in the current frame. The objective of this lab is to modify this code in order to segment red, violet, and yellow colors as well as blue.  In the original base code in order to generate a new image that contains the segmented color objects, we must perform a AND bit-wise operation between the current frame and the mask image, so that only those pixels with high intensity values in the mask image will be recovered from the current frame; whereas the rest will be depicted in black in the blue object.\n",
    "\n",
    "With the help of the GIMP application we were able find out the hue intensity values for the red, violet, and yellow colors. Each color must be asigned with its hue intensity parameters, threshold the hsv image so that only the respective color pixels are kept, perform an AND-bitwise operation between the mask and input images, and finally the visualisation of the mask, the frame, and the segmented color object. The resulting code is shown below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-203a65dd54b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# grab current frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mcf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# convert BGR to HSV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\tchange_colour_space.py\n",
    "\t\n",
    "\tThis code segments several color objects. Then makes an \n",
    "\tAND-bitwise operation between the mask and input images.\n",
    "\tauthor: Miguel Benavides, Laura Morales\n",
    "\tdate created: 13 Marz 2018\n",
    "\tuniversidad de monterrey\n",
    "\"\"\"\n",
    "\n",
    "# import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# initialise a video capture object\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if cap.isOpened() == False:\n",
    "\tprint('Unable to open the camera')\n",
    "\texit()\n",
    "\n",
    "while(True):\n",
    "\n",
    "\t# grab current frame\n",
    "\tcf, frame = cap.read()\n",
    "\n",
    "\t# convert BGR to HSV\n",
    "\thsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "\n",
    "\t# ----- Tune these parameters so that blue-colour  ------ #\n",
    "\t# ----- objects can be detected                    ------ #\n",
    "\th_val_l = 80\n",
    "\th_val_h = 120\n",
    "\ts_val_l = 100\n",
    "\tv_val_l = 100\n",
    "\tlower_blue = np.array([h_val_l,s_val_l, v_val_l])\n",
    "\tupper_blue = np.array([h_val_h, 255, 255])\n",
    "\t# ------------------------------------------------------- #\n",
    "\n",
    "\t# ----- Tune these parameters so that red-colour   ------ #\n",
    "\t# ----- objects can be detected                    ------ #\n",
    "\th_val_l = 160\n",
    "\th_val_h = 200\n",
    "\ts_val_l = 100\n",
    "\tv_val_l = 100\n",
    "\tlower_red = np.array([h_val_l,s_val_l, v_val_l])\n",
    "\tupper_red = np.array([h_val_h, 255, 255])\n",
    "\t# ------------------------------------------------------- #\n",
    "\n",
    "\t# ----- Tune these parameters so that yellow-colour------ #\n",
    "\t# ----- objects can be detected                    ------ #\n",
    "\th_val_l = 10\n",
    "\th_val_h = 50\n",
    "\ts_val_l = 100\n",
    "\tv_val_l = 100\n",
    "\tlower_yellow = np.array([h_val_l,s_val_l, v_val_l])\n",
    "\tupper_yellow = np.array([h_val_h, 255, 255])\n",
    "\t# ------------------------------------------------------- #\n",
    "\n",
    "\t# ----- Tune these parameters so that violet-colour------ #\n",
    "\t# ----- objects can be detected                    ------ #\n",
    "\th_val_l = 130\n",
    "\th_val_h = 170\n",
    "\ts_val_l = 100\n",
    "\tv_val_l = 100\n",
    "\tlower_violet = np.array([h_val_l,s_val_l, v_val_l])\n",
    "\tupper_violet = np.array([h_val_h, 255, 255])\n",
    "\t# ------------------------------------------------------- #\n",
    "\n",
    "\n",
    "\t# threshold the hsv image so that only the respective colour pixels are kept\n",
    "\tmaskblue = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "\tmaskred = cv2.inRange(hsv, lower_red, upper_red)\n",
    "\tmaskyellow = cv2.inRange(hsv, lower_yellow, upper_yellow)\n",
    "\tmaskviolet = cv2.inRange(hsv, lower_violet, upper_violet)\n",
    "\n",
    "\t# AND-bitwise operation between the mask and input images\n",
    "\tblue_object_img = cv2.bitwise_and(frame, frame, mask=maskblue)\n",
    "\tred_object_img = cv2.bitwise_and(frame, frame, mask=maskred)\n",
    "\tyellow_object_img = cv2.bitwise_and(frame, frame, mask=maskyellow)\n",
    "\tviolet_object_img = cv2.bitwise_and(frame, frame, mask=maskviolet)\n",
    "\n",
    "\t# ADD operation between the 4 colours images\n",
    "\tmulticolour_object_img = cv2.add(blue_object_img, red_object_img)\n",
    "\tmulticolour_object_img = cv2.add(multicolour_object_img, yellow_object_img)\n",
    "\tmulticolour_object_img = cv2.add(multicolour_object_img, violet_object_img)\n",
    "\n",
    "\t# visualise current frame\n",
    "\tcv2.imshow('frame',frame)\n",
    "\n",
    "\t# visualise mask image\n",
    "\tcv2.imshow('maskblue', maskblue)\n",
    "\tcv2.imshow('maskred', maskred)\n",
    "\tcv2.imshow('maskyellow', maskyellow)\n",
    "\tcv2.imshow('maskviolet', maskviolet)\n",
    "\n",
    "\t# visualise segmented blue object\n",
    "\tcv2.imshow('blue object', blue_object_img)\n",
    "\tcv2.imshow('red object', red_object_img)\n",
    "\tcv2.imshow('yellow object', yellow_object_img)\n",
    "\tcv2.imshow('violet object', violet_object_img)\n",
    "\tcv2.imshow('multicolour object', multicolour_object_img)\n",
    "\n",
    "\t# Display the resulting frame\n",
    "\tif cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "\t\tbreak\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "Laura: This practice was very interesting because we worked with live video and it opened my mind about a lot of possible applications for this computer vision technology for everyday purposes and industry-related ones. It also helped me understand about the different existing color spaces and to identify for which application each one is more suitable.\n",
    "\n",
    "Miguel: In this lab I learned how to capture several given colors from live video or a video file. The code given was able to distinguish only the blue color, and with the help of the tutorial given by the professor, I was able to extend it to recognize up to 4 different colors. This could be useful, for example, in a car camera, to recognize the lines in the street, given that they are white or yellow.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
