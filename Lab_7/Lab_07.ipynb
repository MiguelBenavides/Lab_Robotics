{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universidad de Monterrey\n",
    "\n",
    "## División de Ingenierías\n",
    "\n",
    "### Lab - Robotics\n",
    "\n",
    "Lab 7: Spatial Filtering\n",
    "\n",
    "Authors: Laura Morales, Miguel Benavides\n",
    "\n",
    "\n",
    "### Table of contents\n",
    "* [Introduction](#introduction)\n",
    "* [Procedure](#procedure)\n",
    "    * [Fundamentals of Spatial Filtering](#spatialfiltering)\n",
    "    * [Spatial Correlation and Convolution](#correlation)\n",
    "    * [Smoothing Spatial Filters](#spatialfilters)\n",
    "        * [Blur](#blur)\n",
    "        * [Gaussian Blur](#gaussianblur)\n",
    "        * [Median Blur](#medianblur)\n",
    "* [Conclusions](#conclusions)\n",
    "* [Bibliography](#bibliography)\n",
    "       \n",
    "\n",
    "\n",
    "### Introduction <a name=\"introduction\"></a>\n",
    "\n",
    "The following lab consists of a series of codes that will help us understand and practice the subjects of image processing, image enhacement, and spatial filtering. We will learn how to use the following methods from the Open CV library:\n",
    "\n",
    "* `cv2.filter2D()`\n",
    "* `cv2.flip()`\n",
    "* `cv2.blur()`\n",
    "* `cv2.GaussianBlur()`\n",
    "* `cv2.medianBlur()`\n",
    "\n",
    "\n",
    "### Procedure <a name=\"procedure\"></a>\n",
    "\n",
    "For this practice, as well as the previous ones, the following tools are required:\n",
    "\n",
    "* Raspberry Pi with WiFi connection capabilities\n",
    "* Jupyter Notebook\n",
    "* Python >= 3.5.2\n",
    "* OpenCV 3.2\n",
    "* Git\n",
    "* GitHub account\n",
    "* Markdown editor (recommended: ReText 5.3.1)\n",
    "\n",
    "The base codes for each of the practices were provided by the instructor but the authors of this report also contributed to the program in order to accomplish the desired objective.\n",
    "\n",
    "\n",
    "### Fundamentals of Spatial Filtering <a name=\"spatialfiltering\"></a>\n",
    "\n",
    "A spatial filter is an optical device which uses the principles of Fourier optics to alter the structure of a beam of light or other electromagnetic radiation, typically coherent laser light. Spatial filtering is commonly used to \"clean up\" the output of lasers, removing aberrations in the beam due to imperfect, dirty, or damaged optics, or due to variations in the laser gain medium itself.\n",
    "\n",
    "Therefore, spatial filtering on image processing is a technique for modifying or enhancing an image which consists of moving the origin of the neighborhood from pixel to pixel and applying an operator T to the pixels in the neighborhood to yield the output at that location. \n",
    "\n",
    "The following code is a basic example demostrating the difference between correlation and convolution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c75f7873a3d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# define function `f`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\tconvolve_f_with_w.py\n",
    "\t\n",
    "\tThis code demonstrates the correct funcionality of\n",
    "\tconvolution and correlation bia a simple example\n",
    "\tof an array f and a kernel w\n",
    "\tauthor: Miguel Benavides, Laura Morales\n",
    "\tdate created: 23 Marz 2018\n",
    "\tuniversidad de monterrey\n",
    "\"\"\"\n",
    "\n",
    "# import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# define function `f`\n",
    "f = np.array([[0, 0, 0, 0, 0], \n",
    "              [0, 0, 0, 0, 0], \n",
    "\t      [0, 0, 1, 0, 0], \n",
    "              [0, 0, 0, 0, 0],\n",
    "\t      [0, 0, 0, 0, 0]], np.float32)\n",
    "\n",
    "# define a 5x5 kernel\n",
    "kernel = np.array([[1, 2, 3], \n",
    "                   [4, 5, 6], \n",
    "                   [7, 8, 9]], np.float32)\n",
    "\n",
    "# compute correlation\n",
    "correlation = cv2.filter2D(f, -1, kernel)\n",
    "\n",
    "# re-rotate the kernel `w` by 180 deg using cv2.flip()\n",
    "kernel_rotated = cv2.flip(kernel, -1)\n",
    "\n",
    "# conpute convolution\n",
    "convolution = cv2.filter2D(f, -1, kernel_rotated)\n",
    "\n",
    "# display correlation values\n",
    "print('\\nCorrelation:\\n', correlation)\n",
    "\n",
    "# display convolution values\n",
    "print('\\nConvolution:\\n', convolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial Correlation and Convolution <a name=\"correlation\"></a>\n",
    "\n",
    "As seen above, the other two terms that we learned are from this lab are: correlation and convolution. Correlation is a statistical technique that can show whether and how strongly pairs of variables are related, which translated to image processing means that it is a process that compares a filter over the original image and computes the sum of products at each location. Convolution, on the other hand, is the combination of two original functions, but in this case, the mechanics are pretty much the same, except that that the filter is first rotated by 180 deg, which is done by the `cv2.flip()` method.  \n",
    "\n",
    "The following code shows and explains the use of the 180 degrees flipped array. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-6f581fd924ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# read image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\tconvolve_image_with_kernel.py\n",
    "\t\n",
    "\tThis code correlates and convolves an image \n",
    "\twith a 5x5 kernel of ones, making a blurred image as a result.\n",
    "\tcv2.flip() = this function flips an array (an image is \n",
    "\talso an array of pixel intensity values) by the means of\n",
    "\t0 being horizontal flip, 1 being vertical flip, and \n",
    "\t-1 being on both axis.\n",
    "\tcv2.filter2D() = this function convolves an image with\n",
    "\tthe kernel, the first parameter src is the image or input\n",
    "\tarray, the second parameter dst is the output image\n",
    "\tor output array (this one has a parameter ddepth to be \n",
    "\tspecified, in our case we want the output image to be the same\n",
    "\tdepth as the RGB input image so we use -1), and the last \n",
    "\tparameter kernel which is the convolution kernel.\n",
    "\tAs this code smooths the image by replacing the center\n",
    "\tpixel with the average of its neightborhoood pixels (in a \n",
    "\t5x5 array), replacing the center pixel with a 1x1 array \n",
    "\taverage will result in the same image as the input.\n",
    "\tChanging the kernel size will result on a different level \n",
    "\tof blurriness. If the kernel is small, the image will blurr\n",
    "\ta little, and viceversa.\n",
    "\tThe weighted average filter is not as heavy on hard edges,\n",
    "\tas the average of the image is severely affected by the \n",
    "\tcenter pixel, and soft edges will be blurred more if it is \n",
    "\tsurrounded by hard edges.\n",
    "\tauthor: Miguel Benavides, Laura Morales\n",
    "\tdate created: 23 Marz 2018\n",
    "\tuniversidad de monterrey\n",
    "\"\"\"\n",
    "\n",
    "# import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# read image\n",
    "img_name = 'cavalo_motorizado.jpg'\n",
    "img = cv2.imread(img_name)\n",
    "\n",
    "# verify that image `img` exist\n",
    "if img is None:\n",
    "\tprint('ERROR: image ', img_name, 'could not be read')\n",
    "\texit()\n",
    "\n",
    "# define a 5x5 kernel\n",
    "# kernel = np.ones((31,31), np.float32)/961\n",
    "kernel = np.array([[1, 2, 1], \n",
    "                   [2, 4, 2], \n",
    "                   [1, 2, 1]], np.float32)/16\n",
    "\n",
    "dst_correlation = cv2.filter2D(img, -1, kernel)\n",
    "\n",
    "# rotate kernel\n",
    "kernel_rotated = cv2.flip(kernel, -1)\n",
    "dst_convolution = cv2.filter2D(img, -1, kernel_rotated)\n",
    "\n",
    "# plot input and convolved images\n",
    "plt.figure(1)\n",
    "plt.imshow(img)\n",
    "plt.title('Input image')\n",
    "plt.xticks([]) \n",
    "plt.yticks([])\n",
    "\n",
    "plt.figure(2)\n",
    "plt.imshow(dst_correlation)\n",
    "plt.title('Output image using a 5x5 averaging filter (correlation)')\n",
    "plt.xticks([]) \n",
    "plt.yticks([])\n",
    "\n",
    "plt.figure(3)\n",
    "plt.imshow(dst_convolution)\n",
    "plt.title('Output image using a 5x5 averaging filter (convolution)')\n",
    "plt.xticks([]) \n",
    "plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoothing Spatial Filters <a name=\"spatialfilters\"></a>\n",
    "\n",
    "In this section, we will use the methods:\n",
    "* `cv2.blur()`\n",
    "* `cv2.GaussianBlur()`\n",
    "* `cv2.medianBlur()`\n",
    "\n",
    "In order to complete what is requested, each code is commented and has it's explanation.\n",
    "\n",
    "\n",
    "\n",
    "### Blur <a name=\"blur\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2fe6d3b1b856>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# read image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\tblur_image.py\n",
    "\t\n",
    "\tIn this code we are using cv2.blur(src, ksize) to create \n",
    "\tthe same effect as last codes, but with a simpler\n",
    "\tmethod, the parameters we will use are the image\n",
    "\tinput, and the blurring kernel size. The kernel \n",
    "\twill be convoluted to the image and will apply \n",
    "\tits average to each pixel in the image to create\n",
    "\ta blur effect.\n",
    "\tauthor: Miguel Benavides, Laura Morales \n",
    "\tdate created: 26 Marz 2018\n",
    "\tuniversidad de monterrey\n",
    "\"\"\"\n",
    "\n",
    "# import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# read image\n",
    "img_name = 'cavalo_motorizado.jpg'\n",
    "img = cv2.imread(img_name)\n",
    "\n",
    "# verify that image `img` exist\n",
    "if img is None:\n",
    "\tprint('ERROR: image ', img_name, 'could not be read')\n",
    "\texit()\n",
    "\n",
    "# blur image using `cv2.blur()`\n",
    "kernel_size = (11,11)\n",
    "blurred_image = cv2.blur(img, kernel_size)\n",
    "\n",
    "# plot input and blurred images\n",
    "plt.figure(1)\n",
    "plt.imshow(img)\n",
    "plt.title('Input image')\n",
    "plt.xticks([]) \n",
    "plt.yticks([])\n",
    "\n",
    "plt.figure(2)\n",
    "plt.imshow(blurred_image)\n",
    "plt.title('Output image using cv2.blur(%i,%i)' % (kernel_size[0], kernel_size[1]))\n",
    "plt.xticks([]) \n",
    "plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Blur <a name=\"gaussianblur\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-3a9a638c73ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# read image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\tgaussian_blur_image.py\n",
    "\t\n",
    "\tThis code will use the function gaussianblur(src, ksize, sigmaX)\n",
    "\tto blur an image with an intesity of the gaussan kernel, which\n",
    "\tis affected by an equation where the sigma affects the blurriness.\n",
    "\tWhen only the x sigma is specified, the y sigma is given the same\n",
    "\tvalue. Same parameters apply as in blur() except the sigma. If both \n",
    "\tsigmas are zeros, they are computed from ksize.width and ksize.heigh.\n",
    "\tauthor: Miguel Benavides, Laura Morales \n",
    "\tdate created: 26 Marz 2018\n",
    "\tuniversidad de monterrey\n",
    "\"\"\"\n",
    "\n",
    "# import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# read image\n",
    "img_name = 'cavalo_motorizado.jpg'\n",
    "img = cv2.imread(img_name)\n",
    "\n",
    "# verify that image `img` exist\n",
    "if img is None:\n",
    "\tprint('ERROR: image ', img_name, 'could not be read')\n",
    "\texit()\n",
    "\n",
    "# blur image using `cv2.blur()`\n",
    "kernel_size = (11,11)\n",
    "blurred_image = cv2.GaussianBlur(img, kernel_size, 0)\n",
    "\n",
    "# plot input and blurred images\n",
    "plt.figure(1)\n",
    "plt.imshow(img)\n",
    "plt.title('Input image')\n",
    "plt.xticks([]) \n",
    "plt.yticks([])\n",
    "\n",
    "plt.figure(2)\n",
    "plt.imshow(blurred_image)\n",
    "plt.title('Output image using cv2.blur(%i,%i)' % (kernel_size[0], kernel_size[1]))\n",
    "plt.xticks([]) \n",
    "plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median Blur <a name=\"medianblur\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\tmedian_filter_for_noise_removal.py\n",
    "\t\n",
    "\tThis code filters the noise by applying a median\n",
    "\tfilter, where the median value of a given amunt of\n",
    "\tneighbouring pixels is placed on the center pixel, \n",
    "\tthis cancels out the spike value of a green or red \n",
    "\tpixel. If the variable 'amount' is increased, the \n",
    "\tamount of noise dots is increased and vicecersa, the \n",
    "\tsame goes for the variable ksize, 1 would leave the \n",
    "\timage unaffected, and 5 would filter the image more\n",
    "\tintensely than 3, be aware that only uneven numbers\n",
    "\tare accepted.\n",
    "\tauthor: Miguel Benavides, Laura Morales\n",
    "\tdate created: 26 Marz 2018\n",
    "\tuniversidad de monterrey\n",
    "\"\"\"\n",
    "\n",
    "# import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# read image\n",
    "img_name = 'cavalo_motorizado.jpg'\n",
    "img = cv2.imread(img_name)\n",
    "\n",
    "# verify that image `img` exist\n",
    "if img is None:\n",
    "\tprint('ERROR: image ', img_name, 'could not be read')\n",
    "\texit()\n",
    "\n",
    "# define level of salt & pepper noise\n",
    "s_vs_p = 0.2\t\t\t\t\t\t\t\t\n",
    "amount = 0.15\t\t\t\t\t\t\t\t# <--- change this value\n",
    "\n",
    "# create a copy of input image\n",
    "out = img.copy()\n",
    "\n",
    "# Generate Salt '1' noise\n",
    "num_salt = np.ceil(amount * img.size * s_vs_p)\n",
    "coords = [np.random.randint(0, i - 1, int(num_salt)) for i in img.shape]\n",
    "out[coords] = 255\n",
    "        \n",
    "# Generate Pepper '0' noise\n",
    "num_pepper = np.ceil(amount* img.size * (1. - s_vs_p))\n",
    "coords = [np.random.randint(0, i - 1, int(num_pepper)) for i in img.shape]\n",
    "out[coords] = 0\n",
    "\n",
    "# apply cv2.medianBlur() for noise removal\n",
    "ksize = 5\t\t\t\t\t\t\t\t\t# <--- change this value\n",
    "img_median = cv2.medianBlur(out, ksize)\n",
    "\n",
    "# plot input and blurred images\n",
    "plt.figure(1)\n",
    "plt.imshow(img)\n",
    "plt.title('Input image')\n",
    "plt.xticks([]) \n",
    "plt.yticks([])\n",
    "\n",
    "plt.figure(2)\n",
    "plt.imshow(out)\n",
    "plt.title('Noise')\n",
    "plt.xticks([]) \n",
    "plt.yticks([])\n",
    "\n",
    "plt.figure(3)\n",
    "plt.imshow(img_median)\n",
    "plt.title('Noise')\n",
    "plt.xticks([]) \n",
    "plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions <a name=\"conclusions\"></a>\n",
    "\n",
    "Laura: I think this practice was daring because it required a lot of mathematical knowledge and research in order to remember and fully understand subjects such as correlation and convolution, which I have, saw but honestly have never applied other than for mathematical, hypothetical purposes, but this gave me a new perspective of the uses and importance about correlation and convolution. \n",
    "\n",
    "Miguel: This laboratory was indeed more challenging than the one before it, but the reward is also greater. Because now we know more deeply how do pixels on image behave and can be altered, by simple or complex functions, we can understand and modify or even create more complex code, and in result more efficient code, in regards to images or computer vision. Also, with this laboratory I understood how the blur on images actually works, on a computer mathematic level. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bibliography <a name=\"bibliography\"></a>\n",
    "* Edmund Optics, Understanding Spatial Filters. Recovered on March 26, 2018 from: https://www.edmundoptics.com/resources/application-notes/lasers/understanding-spatial-filters/\n",
    "* Creative Research Systems, Correlation. Recovered on March 26, 2018 from: https://www.surveysystem.com/correlation.html\n",
    "* University of Tartu. Digital Image Processing: 8. Spatial Domain filtering Part I. Recovered on March 26, 2018 from: https://sisu.ut.ee/imageprocessing/book/8\n",
    "* Pritchard, A. (2017). Markdown Cheatsheet. Recovered on March 26, 2018 from: https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet#code\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
