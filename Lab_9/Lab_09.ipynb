{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universidad de Monterrey\n",
    "\n",
    "\n",
    "## División de Ingenierías\n",
    "\n",
    "\n",
    "### Lab - Robotics\n",
    "\n",
    "\n",
    "Lab 9: Line Hough Transform\n",
    "\n",
    "Authors: Laura Morales, Miguel Benavides\n",
    "\n",
    "### Table of contents\n",
    "\n",
    "* Introduction (#introduction)\n",
    "* Procedure (#procedure)\n",
    "   * Line Hough transform (#hough)\n",
    "   * Line detection using OpenCV (#code)\n",
    "* Conclusions (#conclusions)\n",
    "\n",
    "### Introduction  <a name=\"introduction\"></a>\n",
    "\n",
    "The following lab consists on extracting lines from images using the Hough transform. Linear Hough transform is the crucial part in detecting lane lines in an image. Most of computer vision frameworks have a ready function for Hough transform like OpenCV, which is what we will use for this practice. This practice will teach us to create a line detection system that will simulate the ones used for self-driving cars and improve road safety.\n",
    "\n",
    "### Procedure  <a name=\"procedure\"></a>\n",
    "For this practice, as well as the previous ones, the following tools are required:\n",
    "\n",
    " * Raspberry Pi with WiFi connection capabilities\n",
    " * Jupyter Notebook\n",
    " * Python >= 3.5.2\n",
    " * OpenCV 3.2\n",
    " * Git\n",
    " * GitHub account\n",
    " * Markdown editor (recommended: ReText 5.3.1)\n",
    " \n",
    "The base codes for this practice were provided by the instructor but the authors of this report also contributed to the program in order to accomplish the desired objective.\n",
    "\n",
    "### Line Hough Transform  <a name=\"hough\"></a>\n",
    "\n",
    "The Standard Hough Transform returns parameters of detected lines in Polar Coordinate system, which is a vector of couples (rho, theta). The probabilistic Hough line transform hi the most efficient implementation of Hough transform. It gives as output the extremes of the detected lines (x0, y0, x1, y1). It is difficult to detect straight lines which are part of a curve because they are very very small. For detecting such lines it is important to properly set all the parameters of Hough transform. Two of most important parameters are: Hough votes and maximum distance between points which are to be joined to make a line. Both parameters are set at their minimum value. \n",
    "\n",
    "\n",
    "### Line Detection using OpenCV  <a name=\"code\"></a>\n",
    "\n",
    "The following code uses the Hough transform and the base code provided by the teacher in order to detect the road lines from a video file.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "\n",
    "# select a region of interest\n",
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)\n",
    "\n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "\n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color\n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "\n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "\n",
    "    #cv2.namedWindow('Line detection', cv2.WINDOW_NORMAL)\n",
    "    #cv2.resizeWindow('Line detection', 900, 550)\t    \n",
    "    #cv2.imshow('Line detection',masked_image)\n",
    "\n",
    "    return masked_image\n",
    "\n",
    "def draw_lines(img, lines, color=[0, 0, 255], thickness=3):\n",
    "\n",
    "    \"\"\"\n",
    "    Draws lines on image.\n",
    "    Once the line is detected, it will render the detected lines\n",
    "    back onto the image itself.\n",
    "    \"\"\"    \n",
    "\n",
    "    # Create a blank image that matches the original in size.\n",
    "    line_img = np.zeros(\n",
    "        (\n",
    "            img.shape[0],\n",
    "            img.shape[1],\n",
    "            3\n",
    "        ),\n",
    "        dtype=np.uint8\n",
    "    )\n",
    "\n",
    "    # Make a copy of the original image.\n",
    "    img = np.copy(img)\n",
    "    \n",
    "    # If there are no lines to draw, exit.\n",
    "    if lines is None:\n",
    "        return\n",
    "\n",
    "    # Loop over all lines and draw them on the blank image.\n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            cv2.line(line_img, (x1, y1), (x2, y2), color, thickness)\n",
    "    \n",
    "    # Merge the image with the lines onto the original.\n",
    "    img = cv2.addWeighted(img, 0.8, line_img, 1.0, 0.0)\n",
    "    \n",
    "    # Return the modified image.\n",
    "    return img\n",
    "\n",
    "def pipeline(image):\n",
    "    \"\"\"\n",
    "    An image processing pipeline which will output\n",
    "    an image with the lane lines annotated.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1.- Read image\n",
    "    img_colour = image\n",
    "\n",
    "    # verify that image `img` exist\n",
    "    if img_colour is None:\n",
    "        print('ERROR: image ', img_name, 'could not be read')\n",
    "        exit()\n",
    "\n",
    "\t# 2. Convert from BGR to RGB then from RGB to greyscale\n",
    "    img_colour_rgb = cv2.cvtColor(img_colour, cv2.COLOR_BGR2RGB)\n",
    "    grey = cv2.cvtColor(img_colour_rgb, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "\t# 3.- Apply Gaussuan smoothing\n",
    "    kernel_size = (7,7)\n",
    "    blur_grey = cv2.GaussianBlur(grey, kernel_size, sigmaX=0, sigmaY=0)\n",
    "\n",
    "\t# 4.- Apply Canny edge detector\n",
    "    low_threshold = 10\n",
    "    high_threshold = 70\n",
    "    edges = cv2.Canny(blur_grey, low_threshold, high_threshold, apertureSize=3)\n",
    "\n",
    "\t# 5.- Define a polygon-shape like region of interest\n",
    "    img_shape = grey.shape\n",
    "\n",
    "    # uncomment the following lines when extracting lines around the whole image\n",
    "    '''\n",
    "    img_size = img_shape\n",
    "    bottom_left = (0, img_size[0])\n",
    "    top_left = (0, 0)\n",
    "    top_right = (img_size[1], 0)\n",
    "    bottom_right = (img_size[1], img_size[0])\n",
    "    '''\n",
    "\n",
    "\t# comment the following lines when extracting lines around the roi\n",
    "    bottom_left = (430, 840)\n",
    "    top_left = (900, 580)\n",
    "    top_right = (1020, 580)\n",
    "    bottom_right = (1530, 838)\n",
    "\n",
    "    # create a vertices array that will be used for the roi\n",
    "    vertices = np.array([[bottom_left,top_left, top_right, bottom_right]], dtype=np.int32)\n",
    "\n",
    "\t# 6.- Get a region of interest using the just created polygon. This will be\n",
    "\t#     used together with the Hough transform to obtain the estimated Hough lines\n",
    "    masked_edges = region_of_interest(edges, vertices)\n",
    "\n",
    "\t# 7.- Apply Hough transform for lane lines detection\n",
    "    rho = 1                       # distance resolution in pixels of the Hough grid\n",
    "    theta = np.pi/180             # angular resolution in radians of the Hough grid\n",
    "    threshold = 40                # minimum number of votes (intersections in Hough grid cell)\n",
    "    min_line_len = 5              # minimum number of pixels making up a line\n",
    "    max_line_gap = 5              # maximum gap in pixels between connectable line segments\n",
    "    line_image = np.copy(img_colour)*0   # creating a blank to draw lines on\n",
    "    hough_lines = cv2.HoughLinesP(masked_edges, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    " \n",
    "    left_line_x = []\n",
    "    left_line_y = []\n",
    "    right_line_x = []\n",
    "    right_line_y = []\n",
    " \n",
    "    for line in hough_lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            slope = (y2 - y1) / (x2 - x1) # <-- Calculating the slope.\n",
    "            if math.fabs(slope) < 0.5: # <-- Only consider extreme slope\n",
    "                continue\n",
    "            if slope <= 0: # <-- If the slope is negative, left group.\n",
    "                left_line_x.extend([x1, x2])\n",
    "                left_line_y.extend([y1, y2])\n",
    "            else: # <-- Otherwise, right group.\n",
    "                right_line_x.extend([x1, x2])\n",
    "                right_line_y.extend([y1, y2])\n",
    "\n",
    "    min_y = int(image.shape[0] * (2.8 / 5))\n",
    "    max_y = int(image.shape[0] * (3.9 / 5))\n",
    "\n",
    "    if left_line_x is not None:\n",
    "        if left_line_y is not None:\n",
    "            poly_left = np.poly1d(np.polyfit(\n",
    "                left_line_y,\n",
    "                left_line_x,\n",
    "                deg=1\n",
    "            ))\n",
    " \n",
    "    left_x_start = int(poly_left(max_y))\n",
    "    left_x_end = int(poly_left(min_y))\n",
    "    \n",
    "    if left_line_x is not None:\n",
    "        if left_line_y is not None:\n",
    "            poly_right = np.poly1d(np.polyfit(\n",
    "            right_line_y,\n",
    "            right_line_x,\n",
    "            deg=1\n",
    "        ))\n",
    " \n",
    "    right_x_start = int(poly_right(max_y))\n",
    "    right_x_end = int(poly_right(min_y))\n",
    "    line_image = draw_lines(\n",
    "        image,\n",
    "        [[\n",
    "            [left_x_start, max_y, left_x_end, min_y],\n",
    "            [right_x_start, max_y, right_x_end, min_y],\n",
    "        ]],\n",
    "        thickness=5,\n",
    "    )\n",
    "    return line_image\n",
    "\n",
    "#from moviepy.editor import VideoFileClip\n",
    "#from IPython.display import HTML\n",
    "#white_output = 'highway_right_solid_white_line_short_with_red_lines.mp4'\n",
    "#clip1 = VideoFileClip(\"highway_right_solid_white_line_short.mp4\")\n",
    "#white_clip = clip1.fl_image(pipeline)\n",
    "#white_clip.write_videofile(white_output, audio=False)\n",
    "\n",
    "\n",
    "\n",
    "# visualise output video\n",
    "# create a VideoCapture object and specify video file to be read\n",
    "cap = cv2.VideoCapture('highway_right_solid_white_line_short.mp4')\n",
    "\n",
    "# main loop\n",
    "while(cap.isOpened()):\n",
    "\n",
    "    # read current frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # convert from colour to grayscale image\n",
    "    #img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # run pipeline\n",
    "    line_image = pipeline(frame)\n",
    "    \n",
    "    cv2.namedWindow('Line detection', cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow('Line detection', 900, 550)\t    \n",
    "    cv2.imshow('Line detection',line_image)\n",
    "\n",
    "    # wait for the user to press 'q' to exit \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# release VideoCapture object\n",
    "cap.release()\n",
    "\n",
    "# destroy windows to free memory\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions  <a name=\"conclusion\"></a>\n",
    "\n",
    "Miguel:\n",
    "\n",
    "Laura: This practice was very interesting and defying since there are a lot of manipulations the image must go through to perform the hough transform and be able to detect the road lines. It was also the first time that we were able to detect figures from a video file, this is definitely very useful to understand the processing of images that self-driving cars do. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
