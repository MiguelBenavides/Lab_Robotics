{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Universidad de Monterrey\n",
    "\n",
    "## División de Ingenierías\n",
    "\n",
    "### Lab - Robotics\n",
    "\n",
    "Final Project\n",
    "\n",
    "Authors: Miguel Benavides, Laura Morales\n",
    "\n",
    "\n",
    "### Table of Contents\n",
    "* [Introduction](#introduction) \n",
    "* [Procedure](#procedure)\n",
    "* [Fundamentals of OCR](#ocr)\n",
    "* [Training Code](#code1)\n",
    "* [Testing Code](#code2)\n",
    "* [Conclusions](#conclusions)\n",
    "* [Bibliography](#bibliography)\n",
    "\n",
    "\n",
    "\n",
    "### Introduction <a name=\"introduction\"></a>\n",
    "\n",
    "For this final practice we will put into test what we have learned throughout the semester, in this case, we decided to work with optical character recognition because we thought it was a very useful process with countless applications in the industry and in everyday life such as license plate recognition, quality assurance for manufacturing products and labels, and with further improvement, it could be used as a translator for real life posters or information signs.  \n",
    "\n",
    "\n",
    "\n",
    "### Procedure <a name=\"procedure\"></a>\n",
    "\n",
    "We will use the same tools used thorughout the semester:\n",
    "\n",
    "* Raspberry Pi with WiFi connection capabilities\n",
    "* Jupyter Notebook\n",
    "* Python >= 3.5.2\n",
    "* OpenCV 3.2\n",
    "* Git\n",
    "* GitHub account\n",
    "* Markdown editor (recommended: ReText 5.3.1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Fundamentals of OCR <a name=\"ocr\"></a>\n",
    "\n",
    "Optical Character Recognition, or OCR, is a technology that enables you to convert different types of documents, such as scanned paper documents, PDF files or images captured by a digital camera into editable and searchable data. \n",
    "\n",
    "The exact mechanisms that allow humans to recognize objects are yet to be understood, but the three basic principles are already well known by scientists – integrity, purposefulness and adaptability (IPA). These principles constitute the core of ABBYY FineReader OCR allowing it to replicate natural or human-like recognition.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Training Code  <a name=\"code1\"></a>\n",
    "\n",
    "In a very general explanation, this code first detects blue objects and then creates a mask of it. After this, with the method Canny() it detects the edges, then it applies figure recognition to search for squares and creates a region of interest inside of the smallest square to do a number detection of it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    " \n",
    "im = cv2.imread('training_image.png')\n",
    "if im is None:\n",
    "    print (\"Image not found.\")\n",
    "im3 = im.copy()\n",
    " \n",
    "gray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n",
    "blur = cv2.GaussianBlur(gray,(5,5),0)\n",
    "thresh = cv2.adaptiveThreshold(blur,255,1,1,11,2)\n",
    " \n",
    "#################      Now finding Contours         ###################\n",
    " \n",
    "_,contours,hierarchy = cv2.findContours(thresh,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\n",
    " \n",
    "samples =  np.empty((0,100))\n",
    "responses = []\n",
    "keys = [i for i in range(48,58)]\n",
    " \n",
    "for cnt in contours:\n",
    "    if cv2.contourArea(cnt)>50:\n",
    "        [x,y,w,h] = cv2.boundingRect(cnt)\n",
    " \n",
    "        if  h>28:\n",
    "            cv2.rectangle(im,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "            roi = thresh[y:y+h,x:x+w]\n",
    "            roismall = cv2.resize(roi,(10,10))\n",
    "            cv2.imshow('norm',im)\n",
    "            key = cv2.waitKey(0)\n",
    " \n",
    "            if key == 27:  # (escape to quit)\n",
    "                sys.exit()\n",
    "            elif key in keys:\n",
    "                responses.append(int(chr(key)))\n",
    "                sample = roismall.reshape((1,100))\n",
    "                samples = np.append(samples,sample,0)\n",
    " \n",
    "responses = np.array(responses,np.float32)\n",
    "responses = responses.reshape((responses.size,1))\n",
    "print (\"training complete\")\n",
    " \n",
    "np.savetxt('generalsamples.data',samples)\n",
    "np.savetxt('generalresponses.data',responses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing code  <a name=\"code2\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\ttesting_code.py\n",
    "\t\n",
    "\tThis code segments blue color objects. Then makes an \n",
    "\tAND-bitwise operation between the mask and input images. \n",
    "\tWith the resulting blue mask image then creates a roi, \n",
    "\tinside this region numbers can be detected.\n",
    "\n",
    "\tauthor: Miguel Benavides, Laura Morales\n",
    "\tdate created: 9 May 2018\n",
    "\tuniversidad de monterrey\n",
    "\"\"\"\n",
    "\n",
    "# import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import time\n",
    " \n",
    "#######   training part   ############# \n",
    "samples = np.loadtxt('generalsamples.data',np.float32)\n",
    "responses = np.loadtxt('generalresponses.data',np.float32)\n",
    "responses = responses.reshape((responses.size,1))\n",
    " \n",
    "model = cv2.ml.KNearest_create()\n",
    "model.train(samples,cv2.ml.ROW_SAMPLE,responses)\n",
    " \n",
    "#######   testing part    #############\n",
    "\n",
    "#Frame width & Height\n",
    "w=640\n",
    "h=480\n",
    "\n",
    "def order_points(pts):\n",
    "        # initialzie a list of coordinates that will be ordered\n",
    "        # such that the first entry in the list is the top-left,\n",
    "        # the second entry is the top-right, the third is the\n",
    "        # bottom-right, and the fourth is the bottom-left\n",
    "        rect = np.zeros((4, 2), dtype = \"float32\")\n",
    "\n",
    "        # the top-left point will have the smallest sum, whereas\n",
    "        # the bottom-right point will have the largest sum\n",
    "        s = pts.sum(axis = 1)\n",
    "        rect[0] = pts[np.argmin(s)]\n",
    "        rect[2] = pts[np.argmax(s)]\n",
    "\n",
    "        # now, compute the difference between the points, the\n",
    "        # top-right point will have the smallest difference,\n",
    "        # whereas the bottom-left will have the largest difference\n",
    "        diff = np.diff(pts, axis = 1)\n",
    "        rect[1] = pts[np.argmin(diff)]\n",
    "        rect[3] = pts[np.argmax(diff)]\n",
    "\n",
    "        # return the ordered coordinates\n",
    "        return rect\n",
    "\n",
    "def four_point_transform(image, pts):\n",
    "        # obtain a consistent order of the points and unpack them\n",
    "        # individually\n",
    "        rect = order_points(pts)\n",
    "        (tl, tr, br, bl) = rect\n",
    "\n",
    "        maxWidth = w/2\n",
    "        maxHeight = h/2\n",
    "\n",
    "        dst = np.array([\n",
    "                [0, 0],\n",
    "                [maxWidth - 1, 0],\n",
    "                [maxWidth - 1, maxHeight - 1],\n",
    "                [0, maxHeight - 1]], dtype = \"float32\")\n",
    "\n",
    "        # compute the perspective transform matrix and then apply it\n",
    "        M = cv2.getPerspectiveTransform(rect, dst)\n",
    "        warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
    "\n",
    "        # return the warped image\n",
    "        return warped\n",
    "\n",
    "def auto_canny(image, sigma=0.33):\n",
    "        # compute the median of the single channel pixel intensities\n",
    "        v = np.median(image)\n",
    "\n",
    "        # apply automatic Canny edge detection using the computed median\n",
    "        lower = int(max(0, (1.0 - sigma) * v))\n",
    "        upper = int(min(255, (1.0 + sigma) * v))\n",
    "        edged = cv2.Canny(image, lower, upper)\n",
    "\n",
    "        # return the edged image\n",
    "        return edged\n",
    "\n",
    "def resize_and_threshold_warped(image):\n",
    "        #Resize the corrected image to proper size & convert it to grayscale\n",
    "        #warped_new =  cv2.resize(image,(w/2, h/2))\n",
    "        warped_new_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        #Smoothing Out Image\n",
    "        blur = cv2.GaussianBlur(warped_new_gray,(5,5),0)\n",
    "\n",
    "        #Calculate the maximum pixel and minimum pixel value & compute threshold\n",
    "        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(blur)\n",
    "        threshold = (min_val + max_val)/2\n",
    "\n",
    "        #Threshold the image\n",
    "        ret, warped_processed = cv2.threshold(warped_new_gray, threshold, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        #return the thresholded image\n",
    "        return warped_processed\n",
    "\n",
    "#Font Type\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "# create a VideoCapture object\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if cap.isOpened() == False:\n",
    "\tprint('Unable to open the camera')\n",
    "\texit()\n",
    "\n",
    "# main loop\n",
    "while(True):\n",
    "\n",
    "    # capture new frame\n",
    "    ret, frame = cap.read()\n",
    " \n",
    "    # convert BGR to HSV\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # ----- Tune these parameters so that blue-colour  ------ #\n",
    "    # ----- objects can be detected                    ------ #\n",
    "    h_val_l = 80\n",
    "    h_val_h = 120\n",
    "    s_val_l = 100\n",
    "    v_val_l = 100\n",
    "    lower_blue = np.array([h_val_l,s_val_l, v_val_l])\n",
    "    upper_blue = np.array([h_val_h, 255, 255])\n",
    "    # ------------------------------------------------------- #\n",
    "\n",
    "    # threshold the hsv image so that only the respective colour pixels are kept\n",
    "    maskblue = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "\n",
    "    # AND-bitwise operation between the mask and input images\n",
    "    blue_object_img = cv2.bitwise_and(frame, frame, mask=maskblue)\n",
    "\n",
    "    # visualise current frame\n",
    "    cv2.imshow('frame',frame)\n",
    "\n",
    "    # visualise mask image\n",
    "    cv2.imshow('maskblue', maskblue)\n",
    "\n",
    "    # visualise segmented blue object\n",
    "    cv2.imshow('blue object', blue_object_img)\n",
    "\n",
    "#######   Use the mask to create roi   #######\n",
    "    blurred = cv2.GaussianBlur(maskblue,(3,3),0)\n",
    "\n",
    "    #Detecting Edges\n",
    "    edges = auto_canny(blurred)\n",
    "\n",
    "    #Contour Detection & checking for squares based on the square area\n",
    "    cntr_frame, contours, hierarchy = cv2.findContours(edges,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    smallerArea = 0\n",
    "    smallerContours = 0\n",
    "    for cnt in contours:\n",
    "        approx = cv2.approxPolyDP(cnt,0.01*cv2.arcLength(cnt,True),True)\n",
    "\n",
    "        if len(approx)==4:\n",
    "            area = cv2.contourArea(approx)\n",
    "            \n",
    "            if smallerArea == 0:\n",
    "                smallerArea = area\n",
    "\n",
    "            if area <= smallerArea:\n",
    "                smallerArea = area\n",
    "                smallerContours = [approx]\n",
    "     \n",
    "            if smallerArea > 5000 and smallerArea < 15000:\n",
    "                cv2.drawContours(frame,smallerContours,0,(0,0,255),2)\n",
    "    \n",
    "    cv2.imshow('Edges', edges)\n",
    "    cv2.imshow('Square detection', frame)\n",
    "\n",
    "    ###Create black image to use as mask\n",
    "    img = np.zeros([480,640,1],dtype=np.uint8)\n",
    "\n",
    "    if smallerContours != 0:\n",
    "        roi = np.array(smallerContours)\n",
    "        roi = roi.reshape(-1)\n",
    "        img[roi[3]+5:roi[5]-5, roi[4]+5:roi[6]-5] = 255\n",
    "\n",
    "    cv2.imshow('mask_image',img)\n",
    "    \n",
    "    img_num = cv2.bitwise_and(frame, frame, mask=img)\n",
    " \n",
    "    cv2.imshow('cropped_image',img_num)\n",
    "\n",
    "    im = img_num\n",
    "\n",
    "    out = np.zeros(im.shape,np.uint8)\n",
    "    gray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n",
    "    thresh = cv2.adaptiveThreshold(gray,255,1,1,11,2)\n",
    " \n",
    "    _,contours,hierarchy = cv2.findContours(thresh,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\t \n",
    "    for cnt in contours:\n",
    "        if cv2.contourArea(cnt)>50:\n",
    "            [x,y,w,h] = cv2.boundingRect(cnt)\n",
    "            cuadrado = h - w\n",
    "            if  h > 28 and cuadrado > 10:\n",
    "                cv2.rectangle(im,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "                roi = thresh[y:y+h,x:x+w]\n",
    "                roismall = cv2.resize(roi,(10,10))\n",
    "                roismall = roismall.reshape((1,100))\n",
    "                roismall = np.float32(roismall)\n",
    "                retval, results, neigh_resp, dists = model.findNearest(roismall, k = 1)\n",
    "                string = str(int((results[0][0])))\n",
    "                print (string)\n",
    "                cv2.putText(out,string,(x,y+h),0,1,(0,255,0))\n",
    "                cv2.imshow('im',im)\n",
    "                cv2.imshow('out',out)\n",
    "                cv2.waitKey(0)\n",
    "\n",
    "    # wait for the user to press 'q' to close the window\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# release VideoCapture object\n",
    "cap.release()\n",
    "\n",
    "# destroy windows to free memory\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions  <a name=\"conclusions\"></a>\n",
    "\n",
    " This practice concludes the Robotics' Lab, for this project we had to apply a lot of knowledge learned from previous practices because there were not a lot of examples online for what we wanted to do, but at the end, thanks to the teacher, and my teammate Miguel, we managed to finish it successfully. I learned a lot in this class and it was very interesting to learn about image processing and filtering and I want to thank Mr. Andres for this course.\n",
    "\n",
    "\n",
    "### Bibliography <a name=\"bibliography\"></a>\n",
    "\n",
    "* ABBY (2017). What is OCR and OCR Technology. Recovered on May the 7th, 2018 from: https://www.abbyy.com/en-ee/finereader/what-is-ocr/\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
